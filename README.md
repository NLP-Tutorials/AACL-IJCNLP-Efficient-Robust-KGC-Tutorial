# AACL-IJCNLP2022_Efficient_Robust_KGC_Tutorial

![](https://img.shields.io/badge/Status-building-brightgreen) ![](https://img.shields.io/badge/PRs-Welcome-red) 

Materials for [AACL2022](https://www.aacl2022.org/Program/tutorials) tutorial: Efficient and Robust Knowledge Graph Construction


## Tutorial abstract [\[PDF\]](/files/tutorial.pdf)

Knowledge graph construction which aims to extract knowledge from the text corpus has appealed to the NLP community researchers. Previous decades have witnessed the remarkable progress of knowledge graph construction on the basis of neural models; however,  those models often cost massive computation or labeled data resources and suffer from unstable inference accounting for biased or adversarial samples. Recently, numerous approaches have been explored to mitigate the efficiency and robustness issues for knowledge graph construction, such as prompt learning and adversarial training. In this tutorial, we aim at bringing interested NLP researchers up to speed about the recent and ongoing techniques for efficient and robust knowledge graph construction. Additionally, our goal is to provide a systematic and up-to-date overview of these methods and reveal new research opportunities to the audience.

#### If you find this tutorial helpful for your work, please kindly cite our paper.

```
@inproceedings{zhang2022efficient,
  title={Knowledge-Augmented Methods for Natural Language Processing},
  author={Zhang, Ningyu and Gui, Tao and Nan, Guoshun},
  booktitle={Proceedings of the 2st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Tutorial Abstracts},
  year={2022}
}
```
